#include <opencv2/core/core.hpp> 
#include <opencv2/highgui/highgui.hpp> 
#include <opencv2/imgproc/imgproc.hpp> 
#include <opencv2/features2d/features2d.hpp>
#include <iostream>  
#include <vector> 
#include "opencv2/calib3d.hpp"


using namespace cv;
using namespace std; 

Point point1, point2; /* vertical points of the bounding box */
int drag = 0;
Rect rect; /* bounding box */
Mat frame, roiImg; /* roiImg - the part of the image in the bounding box */
int select_flag = 0;

void mouseHandler(int event, int x, int y, int flags, void* param)
{
    if (event == CV_EVENT_LBUTTONDOWN && !drag)
    {
        /* left button clicked. ROI selection begins */
        point1 = Point(x, y);
        drag = 1;
    }
     
    if (event == CV_EVENT_MOUSEMOVE && drag)
    {
        /* mouse dragged. ROI being selected */
        Mat img1 = frame.clone();
        point2 = Point(x, y);
        rectangle(img1, point1, point2, CV_RGB(255, 0, 0), 3, 8, 0);
        imshow("preview", img1);
    }
     
    if (event == CV_EVENT_LBUTTONUP && drag)
    {
        point2 = Point(x, y);
        rect = Rect(point1.x,point1.y,x-point1.x,y-point1.y);
        drag = 0;
        roiImg = frame(rect);
    }
     
    if (event == CV_EVENT_LBUTTONUP)
    {
       /* ROI selected */
        
        select_flag = 1;
        drag = 0;
    }
}


int main(int argc, char** argv) 
{ 
Mat cimg_1;
Mat cimg_2;
Mat img_1;// = imread("/home/junjin/Downloads/opencv3test/box/frame_0.png"); 
Mat img_2;// = imread("/home/junjin/Downloads/opencv3test/box/frame_1.png");
VideoCapture cap;
 // open the default camera, use something different from 0 otherwise;
// Check VideoCapture documentation.
if(!cap.open(0))
    return 0;

while(select_flag!=1)
{

cap >> frame;
rectangle(frame, rect, CV_RGB(255, 0, 0), 3, 8, 0);
imshow("preview", frame);
cvSetMouseCallback("preview", mouseHandler, NULL);
 if( waitKey(10) == 27 ) 
 {
roiImg=frame;
       break;
}
}
//cvDestroyWindow("preview");
cimg_1=roiImg.clone();
cvtColor(cimg_1,img_1,CV_BGR2GRAY);
for(;;)
{
    if( waitKey(10) == 27 ) 
        break;
    cap >> frame;
    if( frame.empty() ) break; // end of video stream
  
    cimg_2=frame;
    cvtColor(cimg_2,img_2,CV_BGR2GRAY);
    // -- Step 1: Detect the keypoints using STAR Detector 
    std::vector<KeyPoint> keypoints_1,keypoints_2; 
    // Initiate ORB detector
    Ptr<FeatureDetector> orb = ORB::create();

    orb->detect(img_1, keypoints_1); 
    orb->detect(img_2, keypoints_2);

    // -- Stpe 2: Calculate descriptors (feature vectors) 
    Mat descriptors_1, descriptors_2; 
    orb->compute(img_1, keypoints_1, descriptors_1); 
    orb->compute(img_2, keypoints_2, descriptors_2);

    //-- Step 3: Matching descriptor vectors with a brute force matcher 
    BFMatcher matcher(NORM_HAMMING); 
    std::vector<DMatch> matches; 
    matcher.match(descriptors_1, descriptors_2, matches); 
   
     
    double max_dist = 0; double min_dist = 100;  
    //-- Quick calculation of max and min distances between keypoints  
    for( int i = 0; i < descriptors_1.rows; i++ )  
    {   
        double dist = matches[i].distance;  
        if( dist < min_dist ) min_dist = dist;  
        if( dist > max_dist ) max_dist = dist;  
    }  
    printf("-- Max dist : %f \n", max_dist );  
    printf("-- Min dist : %f \n", min_dist );  
    //-- Draw only "good" matches (i.e. whose distance is less than 0.1*max_dist )  
    //-- PS.- radiusMatch can also be used here.  
    std::vector< DMatch > good_matches;  
    for( int i = 0; i < descriptors_1.rows; i++ )  
    {   
        if( matches[i].distance < 0.6*max_dist )  //0.6*max_dist
        {   
            good_matches.push_back( matches[i]);   
        }  
    }  
  

// -- dwaw matches 
    Mat img_matches;  
 drawMatches(cimg_1, keypoints_1, cimg_2, keypoints_2,  
        good_matches, img_matches, Scalar::all(-1), Scalar::all(-1),  
        vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);  


// localize the object  
std::vector<Point2f> obj;  
std::vector<Point2f> scene;  
  
for (size_t i = 0; i < good_matches.size(); ++i)  
{  
    // get the keypoints from the good matches  
    obj.push_back(keypoints_1[ good_matches[i].queryIdx ].pt);  
    scene.push_back(keypoints_2[ good_matches[i].trainIdx ].pt);  
}  


Mat H = findHomography( obj, scene, CV_RANSAC );  
// get the corners from the image_1  
std::vector<Point2f> obj_corners(4);  
obj_corners[0] = cvPoint(0,0);  
obj_corners[1] = cvPoint( img_1.cols, 0);  
obj_corners[2] = cvPoint( img_1.cols, img_1.rows);  
obj_corners[3] = cvPoint( 0, img_1.rows);  
 printf("-- img_1 : %d \n", img_1.cols );  

std::vector<Point2f> scene_corners(4);  
  
perspectiveTransform( obj_corners, scene_corners, H); 


// draw lines between the corners (the mapped object in the scene - image_2)  
line( img_matches, scene_corners[0] + Point2f( img_1.cols, 0), scene_corners[1] + Point2f( img_1.cols, 0),Scalar(0,255,0),4);  
line( img_matches, scene_corners[1] + Point2f( img_1.cols, 0), scene_corners[2] + Point2f( img_1.cols, 0),Scalar(0,255,0),4);  
line( img_matches, scene_corners[2] + Point2f( img_1.cols, 0), scene_corners[3] + Point2f( img_1.cols, 0),Scalar(0,255,0),4);  
line( img_matches, scene_corners[3] + Point2f( img_1.cols, 0), scene_corners[0] + Point2f( img_1.cols, 0),Scalar(0,255,0),4);  


   
    imshow( "Match", img_matches);  
    waitKey(10);
    //waitKey(0); 

}

  


   
    return 0; 
}
